{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_for_NLP_Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfcWOelWNvC_",
        "colab_type": "text"
      },
      "source": [
        "##**Stage 1 :**  Importing the Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2i1fVqeNtUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from google.colab import drive\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3j4RozdOJHo",
        "colab_type": "code",
        "outputId": "56a4f93e-766c-4d68-b63f-1da146f6d88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-PqTtDePJsl",
        "colab_type": "text"
      },
      "source": [
        "##**Stage 2 :** Data Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1lz-4fjPSC_",
        "colab_type": "code",
        "outputId": "3d8a6ce7-357f-4613-ec58-724c1f3751af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# in case of using google colab , to mount the drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jae2q3ixwLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "# add the path for the dataset\n",
        "train_data = pd.read_csv(\n",
        "    \"/content/drive/My Drive/CNN_for_NLP/data/training.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")\n",
        "# add the path for the dataset\n",
        "test_data = pd.read_csv(\n",
        "    \"/content/drive/My Drive/CNN_for_NLP/data/testing.csv\", \n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lviq8ETkzys7",
        "colab_type": "code",
        "outputId": "69264929-94fe-4ebc-c902-276efa9a62ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_data.head(5)\n",
        "train_data.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_EQ8RYl592n",
        "colab_type": "text"
      },
      "source": [
        "## PreProcessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlvWp6Rz6FWH",
        "colab_type": "text"
      },
      "source": [
        "###Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3CdAOR75yqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.drop([\"id\", \"date\", \"query\",\"user\"],axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Ol1mdf6x-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-0./]+\", ' ', tweet)\n",
        "    tweet = re.sub(r\"[^A-Za-z.?!']\", ' ', tweet)\n",
        "    tweet = re.sub(r\" +\", ' ',tweet)\n",
        "    return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbwBDXAG8s_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in train_data.text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2OB6FV29G-_",
        "colab_type": "code",
        "outputId": "1e95786e-16ad-4f2d-eae7-473510602e93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_labels = train_data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1\n",
        "set(data_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7fOkJRQlyHW",
        "colab_type": "text"
      },
      "source": [
        "###Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBAb7QWGl1k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
        "    data_clean,target_vocab_size=2**16\n",
        ")\n",
        "data_inputs = [tokenizer.encode(sentence) for sentence in data_clean]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfPQ5CJ5nPLs",
        "colab_type": "text"
      },
      "source": [
        "###Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyKh2rITnRYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = max(len(sentence) for sentence in data_inputs)\n",
        "data_inputs = tf.keras.preprocessing.sequence.pad_sequences(data_inputs,\n",
        "                                                            value=0,\n",
        "                                                            padding=\"post\",\n",
        "                                                            maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npeyP-YBq66J",
        "colab_type": "text"
      },
      "source": [
        "###Test/Train Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYUteRGoq9w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_idx = np.random.randint(0, 800000, 8000)\n",
        "test_idx = np.concatenate((test_idx,test_idx+800000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIjWRyFerXlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_inputs = data_inputs[test_idx] \n",
        "test_labels = data_labels[test_idx]\n",
        "train_inputs = np.delete(data_inputs, test_idx, axis=0)\n",
        "train_labels = np.delete(data_labels, test_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWrT0GCQzhgg",
        "colab_type": "text"
      },
      "source": [
        "##**Stage 3 :** Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jcbJCUwzlvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 vocab_size,  emb_dim=128,\n",
        "                 nb_filters=50, FFN_units=512,\n",
        "                 nb_classes=2, dropout_rate=0.1,\n",
        "                 training=False, name=\"dcnn\"):\n",
        "        \n",
        "        super(DCNN, self).__init__(name=name)\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, emb_dim)\n",
        "        # Layer 1\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters, kernel_size=2,\n",
        "                                    padding=\"valid\", activation=\"relu\")\n",
        "        self.pool_1 = layers.GlobalMaxPool1D()\n",
        "       # Layer 2\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters, kernel_size=3,\n",
        "                                    padding=\"valid\", activation=\"relu\")\n",
        "        self.pool_2 = layers.GlobalMaxPool1D()\n",
        "        # Layer 3\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters, kernel_size=4,\n",
        "                                    padding=\"valid\", activation=\"relu\")\n",
        "        self.pool_3 = layers.GlobalMaxPool1D()\n",
        "        # Dense Fully Connected Layer\n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        # Output Layer\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1, activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes, activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x)\n",
        "        x_1 = self.pool_1(x_1)\n",
        "        x_2 = self.trigram(x)\n",
        "        x_2 = self.pool_2(x_2)\n",
        "        x_3 = self.fourgram(x)\n",
        "        x_3 = self.pool_3(x_3)\n",
        "\n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1)   # (batchsize, 3*nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged)\n",
        "        output = self.last_dense(merged)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR0BD0EU4gUH",
        "colab_type": "text"
      },
      "source": [
        "##**Stage 4** : Application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hhGc0oy4muW",
        "colab_type": "text"
      },
      "source": [
        "###Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtvjBgLT4p5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "EMB_DIM = 64\n",
        "NB_FILTERS = 50\n",
        "FFN_UNITS = 128\n",
        "NB_CLASSES = len(set(train_labels))\n",
        "DROPOUT_RATE = 0.1\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI89FAR85ZKG",
        "colab_type": "text"
      },
      "source": [
        "###Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmFAamEe5ben",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE, emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS, FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES, dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGPDyXUs-lIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\", \n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd_HgmsX_g1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this to save the model , give any path to save the model for \n",
        "# future use\n",
        "\n",
        "checkpoint_path = \"./drive/My Drive/CNN_for_NLP/ckpt/\"\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored .\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihV-WJtiBDa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Dcnn.fit(train_inputs,\n",
        "         train_labels,\n",
        "         batch_size = BATCH_SIZE,\n",
        "         epochs=NB_EPOCHS)\n",
        "ckpt_manager.save"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LIH-EFTDML6",
        "colab_type": "text"
      },
      "source": [
        "###Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq-uA71FDOS_",
        "colab_type": "code",
        "outputId": "b1a28808-ac42-40cc-b66c-33128f2e57d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "results = Dcnn.evaluate(test_inputs,\n",
        "                        test_labels,\n",
        "                        batch_size=BATCH_SIZE)\n",
        "print(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500/500 [==============================] - 10s 20ms/step - loss: 0.4614 - accuracy: 0.7809\n",
            "[0.46142998337745667, 0.780875027179718]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akH_uP9YDzLY",
        "colab_type": "code",
        "outputId": "499428f5-e87b-4aca-82c9-9bd631e30589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Dcnn(np.array([tokenizer.encode(\"I hate you\")]), training=False).numpy()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[nan]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    }
  ]
}